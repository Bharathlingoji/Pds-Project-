The problem is to predict the activity given a snapshot of sensor data, typically data from one or a small number of sensor types. Generally, this problem is framed as a univariate or multivariate time series classification task. It is a challenging problem as there are no obvious or direct ways to relate the recorded sensor data to specific human activities and each subject may perform an activity with significant variation, resulting in variations in the recorded sensor data. The intent is to record sensor data and corresponding activities for specific subjects, fit a model from this data, and generalize the model to classify the activity of new unseen subjects from their sensor data.
So to detect the activity in the video, we breakdown the video into frames so that each frame has its own activity name to it. The packages we used in the project are OpenCv, Numpy , Deque, Imutils. The OpenCv is used to open the video frames, deque for storing the images frames in the multidimensional array. Imutiles, used to resize the frame. We use the ONNX file for training our model. The project is executed in the Pycharm. The whole source code is in python thus we need python pre installed in the system to run the model. After executing we get the desired results on each frame of the video stating the recognized human activity. 